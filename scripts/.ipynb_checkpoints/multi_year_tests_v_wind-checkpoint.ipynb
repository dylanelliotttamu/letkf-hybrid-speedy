{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FOR 1981-1992 years of LETKF\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from netCDF4 import Dataset\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import xarray as xr\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from numba import jit\n",
    "\n",
    "@jit()\n",
    "def rms(true,prediction):\n",
    "    return np.sqrt(np.nanmean((prediction-true)**2))\n",
    "\n",
    "@jit()\n",
    "def rms_tendency(variable,hours):\n",
    "    variable_tendency = np.zeros((hours))\n",
    "    variable = np.exp(variable) * 1000.0\n",
    "\n",
    "    for i in range(hours):\n",
    "        variable_tendency[i] = np.sqrt(np.mean((variable[i+1] - variable[i])**2.0))\n",
    "\n",
    "    return variable_tendency\n",
    "\n",
    "def latituded_weighted_rmse(true,prediction,lats):\n",
    "    diff = prediction-true\n",
    "\n",
    "    weights = np.cos(np.deg2rad(lats))\n",
    "\n",
    "    weights2d = np.zeros(np.shape(diff))\n",
    "\n",
    "    diff_squared = diff**2.0\n",
    "    #weights = np.ones((10,96))\n",
    "\n",
    "    weights2d = np.tile(weights,(96,1))\n",
    "    weights2d = np.transpose(weights2d)\n",
    "\n",
    "    masked = np.ma.MaskedArray(diff_squared, mask=np.isnan(diff_squared))\n",
    "    weighted_average = np.ma.average(masked,weights=weights2d)\n",
    "\n",
    "    return np.sqrt(weighted_average)\n",
    "\n",
    "start_year = 1981\n",
    "end_year = 1992\n",
    "\n",
    "startdate = datetime(1981,1,1,0)\n",
    "enddate = datetime(1992,1,1,0)\n",
    "\n",
    "# create empty list to store indiviudal datasets\n",
    "era5sets = []\n",
    "\n",
    "# loop over the range of years and open each ds\n",
    "for year in range(start_year, end_year + 1):\n",
    "    nature_file = f'/skydata2/troyarcomano/ERA_5/{year}/era_5_y{year}_regridded_mpi_fixed_var.nc'\n",
    "    ds_nature = xr.open_dataset(nature_file)\n",
    "    era5sets.append(ds_nature)\n",
    "ds_nature = xr.concat(era5sets, dim = 'Timestep')\n",
    "ds_nature = ds_nature.sortby('Timestep')\n",
    "\n",
    "#nature_file = f'/skydata2/troyarcomano/ERA_5/{start_year}/era_5_y{start_year}_regridded_mpi_fixed_var.nc'\n",
    "\n",
    "analysis_file_speedy = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/uniform_analysis_81_12.nc'\n",
    "analysis_file = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/hybrid_1_5_1_3_19810101_20100101/mean.nc'\n",
    "spread_file =  '/skydata2/troyarcomano/letkf-hybrid-speedy/experiments/hybrid_first_test/anal_sprd.nc'\n",
    "\n",
    "#ds_nature = xr.open_dataset(nature_file)\n",
    "ds_analysis_mean = xr.open_dataset(analysis_file)\n",
    "ds_analysis_mean_speedy = xr.open_dataset(analysis_file_speedy)\n",
    "#ds_spread = xr.open_dataset(spread_file)\n",
    "#print(ds_nature)\n",
    "\n",
    "\n",
    "\n",
    "lats = ds_nature.Lat\n",
    "\n",
    "level = 0.2 #0.2#0.95#0.51\n",
    "level_era = 2 #2#7 #4\n",
    "\n",
    "time_slice = slice(startdate,enddate)\n",
    "\n",
    "var_era = 'V-wind'#'Specific_Humidity'#'Temperature' #'V-wind'\n",
    "var_da =  'v'#'q'#'t'#'v'\n",
    "temp_500_nature = ds_nature[var_era].sel(Sigma_Level=level_era).values\n",
    "temp_500_analysis = ds_analysis_mean[var_da].sel(lev=level).values\n",
    "temp_500_analysis_speedy = ds_analysis_mean_speedy[var_da].sel(lev=level,time=time_slice).values\n",
    "#temp_500_spread = ds_spread[var_da].sel(lev=level).values\n",
    "\n",
    "print('era5 shape = ',np.shape(temp_500_nature))\n",
    "print('speedy shape = ',np.shape(temp_500_analysis_speedy))\n",
    "print('hybrid shape = ',np.shape(temp_500_analysis))\n",
    "\n",
    "#find smallest index value to set that as the \"length\"\n",
    "speedy_index = temp_500_analysis_speedy.shape[0]\n",
    "nature_index = temp_500_nature.shape[0]\n",
    "hybrid_index = temp_500_analysis.shape[0]\n",
    "smallest_index = min(speedy_index,nature_index,hybrid_index)\n",
    "\n",
    "if smallest_index == speedy_index:\n",
    "    length = speedy_index #- 1\n",
    "elif smallest_index == nature_index:\n",
    "    length = nature_index\n",
    "else:\n",
    "    length = hybrid_index\n",
    "print('the smallest length is',length)\n",
    "\n",
    "#ps_nature = ds_nature['logp'].values\n",
    "#ps_nature = 1000.0 * np.exp(ps_nature)\n",
    "#ps_analysis = ds_analysis_mean['ps'].values/100.0\n",
    "\n",
    "xgrid = 96\n",
    "ygrid = 48\n",
    "#length =365*4*2 #1952-7 # 240 for 3 months  #1450 ##338 #160#64#177#1400#455\n",
    "\n",
    "analysis_rmse = np.zeros((length))\n",
    "analysis_rmse_speedy = np.zeros((length))\n",
    "#global_average_ensemble_spread= np.zeros((length))\n",
    "#ps_rmse = np.zeros((length))\n",
    "\n",
    "analysis_error = np.zeros((length,ygrid,xgrid))\n",
    "analysis_error_speedy = np.zeros((length,ygrid,xgrid))\n",
    "\n",
    "print(np.shape(analysis_error))\n",
    "print(np.shape(analysis_error_speedy))\n",
    "for i in range(length):\n",
    "    analysis_rmse[i] = latituded_weighted_rmse(temp_500_nature[i*6,:,:],temp_500_analysis[i,:,:],lats)\n",
    "    analysis_rmse_speedy[i] = latituded_weighted_rmse(temp_500_nature[i*6,:,:],temp_500_analysis_speedy[i,:,:],lats)\n",
    "    #ps_rmse[i] = rms(ps_nature[i*6,:,:],ps_analysis[i,:,:])\n",
    "    analysis_error[i,:,:] = temp_500_analysis[i,:,:] - temp_500_nature[i*6,:,:]\n",
    "    analysis_error_speedy[i,:,:] = temp_500_analysis_speedy[i,:,:] - temp_500_nature[i*6,:,:]\n",
    "    #global_average_ensemble_spread[i] = np.average(temp_500_spread[i,:,:])\n",
    "\n",
    "''' 24(below) instead of 28 to cut transient event (ML spin up) out in first few weeks '''\n",
    "  \n",
    "averaged_error = np.average(abs(analysis_error[24::,:,:]),axis=0)\n",
    "averaged_error_speedy = np.average(abs(analysis_error_speedy[24::,:,:]),axis=0)\n",
    "\n",
    "lat = ds_analysis_mean.lat.values\n",
    "lon = ds_analysis_mean.lon.values\n",
    "\n",
    "lons2d, lats2d = np.meshgrid(lon,lat)\n",
    "\n",
    "fig = plt.figure(figsize=(6,10))\n",
    "''' ax1 ===>  Makes map of hybrid letkf analysis error  '''\n",
    "ax1 = plt.subplot(311,projection=ccrs.PlateCarree())\n",
    "ax1.coastlines()\n",
    "\n",
    "''' Multiply averaged_error by 1000 for spec_humid only'''\n",
    "\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(averaged_error, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "\n",
    "cf = ax1.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(0,10.1,.05),extend='both')\n",
    "plt.colorbar(cf,label='(m/s)')\n",
    "ax1.set_title('Hybrid 1.5,1.3 LETKF Analysis Error\\n 200 hPa Meridional Wind')\n",
    "\n",
    "diff = averaged_error - averaged_error_speedy\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(diff, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "'''ax2 ===>  makes plot of speedy letkf analysis error '''\n",
    "ax2 = plt.subplot(312,projection=ccrs.PlateCarree())\n",
    "ax2.coastlines()\n",
    "\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(averaged_error_speedy, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "\n",
    "cf = ax2.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(0,10.1,.05),extend='both')\n",
    "plt.colorbar(cf,label='(m/s)')\n",
    "ax2.set_title('SPEEDY 1.3 LETKF Analysis Error \\n 200 hPa Meridional Wind')\n",
    "\n",
    "diff = averaged_error - averaged_error_speedy\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(diff, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "\n",
    "'''ax3 ==> Makes map of difference of hybrid and speedy '''\n",
    "\n",
    "ax3 = plt.subplot(313,projection=ccrs.PlateCarree())\n",
    "ax3.coastlines()\n",
    "ax3.set_title('Difference (Hybrid - SPEEDY)')\n",
    "cf = ax3.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(-2,2.1,.01),extend='both',cmap='seismic')\n",
    "\n",
    "#cf = ax3.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(-5,5.1,.5),extend='both',cmap='seismic')\n",
    "plt.colorbar(cf,label='(m/s)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#print('Average RMSE Surface Pressure (hPa)',np.average(ps_rmse))\n",
    "#print('Average RMSE Variable',np.average(ps_rmse))\n",
    "x = np.arange(0,length)\n",
    "\n",
    "base = datetime(1981,1,1,0)\n",
    "\n",
    "date_list = [base + timedelta(days=x/4) for x in range(length)]\n",
    "plt.plot(date_list,analysis_rmse,color='r',label='RMSE Hybrid 1.5,1.3') #cov-infl1.3\n",
    "plt.plot(date_list,analysis_rmse_speedy,color='b',label='RMSE SPEEDY 1.3')\n",
    "plt.axhline(y=np.average(analysis_rmse[20::]), color='r', linestyle='--',linewidth=.1,label=\"Average RMSE Hybrid 1.5,1.3\")\n",
    "plt.axhline(y=np.average(analysis_rmse_speedy[20::]), color='b', linestyle='--',linewidth=.1,label=\"Average RMSE SPEEDY 1.3\")\n",
    "print('average rmse Hybrid', np.average(analysis_rmse[20::]))\n",
    "print('average rmse SPEEDY', np.average(analysis_rmse_speedy[20::]))\n",
    "#plt.plot(date_list,global_average_ensemble_spread,label='Ensemble Spread')\n",
    "#plt.title('LETKF Analysis Error\\n Low Level Specific Humidity')\n",
    "plt.title('LETKF Analysis Error\\n 200 hPa Meridional Wind')\n",
    "#plt.title('Ensemble Spread\\nModel Level 4 Temperature')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Analysis Error')\n",
    "#plt.ylabel('Analysis Error (kg/kg)')\n",
    "#plt.ylabel('Ensemble Spread (K)')\n",
    "plt.xlim([datetime(1981, 1, 1,0), datetime(1993, 2, 1,0)])\n",
    "plt.ylim(3,10)\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "## plot of spin-ups\n",
    "#x= np.arange(0,length)\n",
    "#\n",
    "#date_list = [base + timedelta(days=x/4) for x in range(length)]\n",
    "#plt.plot(date_list,analysis_rmse,color='r',label='RMSE Hybrid ') #cov-infl1.3\n",
    "#plt.plot(date_list,analysis_rmse_speedy,color='b',label='RMSE SPEEDY')\n",
    "#plt.axhline(y=np.average(analysis_rmse[20::]), color='r', linestyle='--',label=\"Average RMSE Hybrid\")\n",
    "#plt.axhline(y=np.average(analysis_rmse_speedy[20::]), color='b', linestyle='--',label=\"Average RMSE SPEEDY\")\n",
    "#print('average rmse Hybrid', np.average(analysis_rmse[20::])) #20\n",
    "#print('average rmse SPEEDY', np.average(analysis_rmse_speedy[20::])) #20\n",
    "##plt.plot(date_list,global_average_ensemble_spread,label='Ensemble Spread')\n",
    "##plt.title('LETKF Analysis Error\\n Low Level Specific Humidity')\n",
    "#plt.title('LETKF Analysis Error\\n 200 hPa Meridional Wind\\n Initial Spin-up')\n",
    "##plt.title('Ensemble Spread\\nModel Level 4 Temperature')\n",
    "#plt.legend()\n",
    "#plt.xlabel('Date')\n",
    "#plt.ylabel('Analysis Error')\n",
    "##plt.ylabel('Analysis Error (kg/kg)')\n",
    "##plt.ylabel('Ensemble Spread (K)')\n",
    "#plt.xlim([datetime(2012, 1, 1,0), datetime(2012, 1, 4,0)])\n",
    "#plt.show()\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56618f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,length)\n",
    "\n",
    "base = datetime(1981,1,1,0)\n",
    "plt.figure(figsize=(12,6))\n",
    "date_list = [base + timedelta(days=x/4) for x in range(length)]\n",
    "plt.plot(date_list,analysis_rmse,color='r',linewidth=.15,label='RMSE Hybrid 1.5,1.3') #cov-infl1.3\n",
    "plt.plot(date_list,analysis_rmse_speedy,color='b',linewidth=.15,label='RMSE SPEEDY 1.3')\n",
    "plt.axhline(y=np.average(analysis_rmse[20::]), color='r', linestyle='--',linewidth=1,label=\"Average RMSE Hybrid 1.5,1.3\")\n",
    "plt.axhline(y=np.average(analysis_rmse_speedy[20::]), color='b', linestyle='--',linewidth=1,label=\"Average RMSE SPEEDY 1.3\")\n",
    "print('average rmse Hybrid = ', np.average(analysis_rmse[20::]))\n",
    "print('average rmse SPEEDY = ', np.average(analysis_rmse_speedy[20::]))\n",
    "#plt.plot(date_list,global_average_ensemble_spread,label='Ensemble Spread')\n",
    "#plt.title('LETKF Analysis Error\\n Low Level Specific Humidity')\n",
    "plt.title('LETKF Analysis Error\\n 200 hPa Meridional Wind')\n",
    "#plt.title('Ensemble Spread\\nModel Level 4 Temperature')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Analysis Error')\n",
    "#plt.ylabel('Analysis Error (kg/kg)')\n",
    "#plt.ylabel('Ensemble Spread (K)')\n",
    "plt.xlim([datetime(1981, 1, 1,0), datetime(1992, 2, 1,0)])\n",
    "plt.ylim(3,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9aafe9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'tisr' is not present in all datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/dataset.py:1395\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tisr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/concat.py:518\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m ensure_common_dims([ds[k]\u001b[38;5;241m.\u001b[39mvariable \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets])\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/concat.py:518\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m ensure_common_dims([\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvariable \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets])\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/dataset.py:1499\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hashable(key):\n\u001b[0;32m-> 1499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_dataarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/dataset.py:1397\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1397\u001b[0m     _, name, variable \u001b[38;5;241m=\u001b[39m \u001b[43m_get_virtual_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_level_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1401\u001b[0m needed_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(variable\u001b[38;5;241m.\u001b[39mdims)\n",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/dataset.py:170\u001b[0m, in \u001b[0;36m_get_virtual_variable\u001b[0;34m(variables, key, level_vars, dim_sizes)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     ref_var \u001b[38;5;241m=\u001b[39m \u001b[43mvariables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mref_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tisr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m     ds_nature \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(nature_file)\n\u001b[1;32m     61\u001b[0m     era5sets\u001b[38;5;241m.\u001b[39mappend(ds_nature)\n\u001b[0;32m---> 62\u001b[0m ds_nature \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mera5sets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTimestep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m ds_nature \u001b[38;5;241m=\u001b[39m ds_nature\u001b[38;5;241m.\u001b[39msortby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestep\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#nature_file = f'/skydata2/troyarcomano/ERA_5/{start_year}/era_5_y{start_year}_regridded_mpi_fixed_var.nc'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/concat.py:242\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only concatenate xarray Dataset and DataArray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(first_obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_attrs\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py_env_plot/lib/python3.8/site-packages/xarray/core/concat.py:520\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m ensure_common_dims([ds[k]\u001b[38;5;241m.\u001b[39mvariable \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets])\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not present in all datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    521\u001b[0m combined \u001b[38;5;241m=\u001b[39m concat_vars(\u001b[38;5;28mvars\u001b[39m, dim, positions, combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(combined, Variable)\n",
      "\u001b[0;31mValueError\u001b[0m: 'tisr' is not present in all datasets."
     ]
    }
   ],
   "source": [
    "# CODE FOR 1992-2003 LETKF \n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from netCDF4 import Dataset\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import xarray as xr\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from numba import jit\n",
    "\n",
    "@jit()\n",
    "def rms(true,prediction):\n",
    "    return np.sqrt(np.nanmean((prediction-true)**2))\n",
    "\n",
    "@jit()\n",
    "def rms_tendency(variable,hours):\n",
    "    variable_tendency = np.zeros((hours))\n",
    "    variable = np.exp(variable) * 1000.0\n",
    "\n",
    "    for i in range(hours):\n",
    "        variable_tendency[i] = np.sqrt(np.mean((variable[i+1] - variable[i])**2.0))\n",
    "\n",
    "    return variable_tendency\n",
    "\n",
    "def latituded_weighted_rmse(true,prediction,lats):\n",
    "    diff = prediction-true\n",
    "\n",
    "    weights = np.cos(np.deg2rad(lats))\n",
    "\n",
    "    weights2d = np.zeros(np.shape(diff))\n",
    "\n",
    "    diff_squared = diff**2.0\n",
    "    #weights = np.ones((10,96))\n",
    "\n",
    "    weights2d = np.tile(weights,(96,1))\n",
    "    weights2d = np.transpose(weights2d)\n",
    "\n",
    "    masked = np.ma.MaskedArray(diff_squared, mask=np.isnan(diff_squared))\n",
    "    weighted_average = np.ma.average(masked,weights=weights2d)\n",
    "\n",
    "    return np.sqrt(weighted_average)\n",
    "\n",
    "start_year = 1992\n",
    "end_year = 2003\n",
    "\n",
    "startdate = datetime(1992,1,1,0)\n",
    "enddate = datetime(2003,1,1,0)\n",
    "\n",
    "# create empty list to store indiviudal datasets\n",
    "era5sets = []\n",
    "\n",
    "# loop over the range of years and open each ds\n",
    "for year in range(start_year, end_year + 1):\n",
    "    nature_file = f'/skydata2/troyarcomano/ERA_5/{year}/era_5_y{year}_regridded_mpi_fixed_var.nc'\n",
    "    ds_nature = xr.open_dataset(nature_file)\n",
    "    era5sets.append(ds_nature)\n",
    "ds_nature = xr.concat(era5sets, dim = 'Timestep')\n",
    "ds_nature = ds_nature.sortby('Timestep')\n",
    "\n",
    "#nature_file = f'/skydata2/troyarcomano/ERA_5/{start_year}/era_5_y{start_year}_regridded_mpi_fixed_var.nc'\n",
    "\n",
    "analysis_file_speedy = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/uniform_analysis_81_12.nc'\n",
    "analysis_file = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/hybrid_1_5_1_3_19810101_20100101/mean.nc'\n",
    "spread_file =  '/skydata2/troyarcomano/letkf-hybrid-speedy/experiments/hybrid_first_test/anal_sprd.nc'\n",
    "\n",
    "#ds_nature = xr.open_dataset(nature_file)\n",
    "ds_analysis_mean = xr.open_dataset(analysis_file)\n",
    "ds_analysis_mean_speedy = xr.open_dataset(analysis_file_speedy)\n",
    "#ds_spread = xr.open_dataset(spread_file)\n",
    "#print(ds_nature)\n",
    "\n",
    "\n",
    "\n",
    "lats = ds_nature.Lat\n",
    "\n",
    "level = 0.2 #0.2#0.95#0.51\n",
    "level_era = 2 #2#7 #4\n",
    "\n",
    "time_slice = slice(startdate,enddate)\n",
    "\n",
    "var_era = 'V-wind'#'Specific_Humidity'#'Temperature' #'V-wind'\n",
    "var_da =  'v'#'q'#'t'#'v'\n",
    "temp_500_nature = ds_nature[var_era].sel(Sigma_Level=level_era).values\n",
    "temp_500_analysis = ds_analysis_mean[var_da].sel(lev=level).values\n",
    "temp_500_analysis_speedy = ds_analysis_mean_speedy[var_da].sel(lev=level,time=time_slice).values\n",
    "#temp_500_spread = ds_spread[var_da].sel(lev=level).values\n",
    "\n",
    "print('era5 shape = ',np.shape(temp_500_nature))\n",
    "print('speedy shape = ',np.shape(temp_500_analysis_speedy))\n",
    "print('hybrid shape = ',np.shape(temp_500_analysis))\n",
    "\n",
    "#find smallest index value to set that as the \"length\"\n",
    "speedy_index = temp_500_analysis_speedy.shape[0]\n",
    "nature_index = temp_500_nature.shape[0]\n",
    "hybrid_index = temp_500_analysis.shape[0]\n",
    "smallest_index = min(speedy_index,nature_index,hybrid_index)\n",
    "\n",
    "if smallest_index == speedy_index:\n",
    "    length = speedy_index #- 1\n",
    "elif smallest_index == nature_index:\n",
    "    length = nature_index\n",
    "else:\n",
    "    length = hybrid_index\n",
    "print('the smallest length is',length)\n",
    "\n",
    "#ps_nature = ds_nature['logp'].values\n",
    "#ps_nature = 1000.0 * np.exp(ps_nature)\n",
    "#ps_analysis = ds_analysis_mean['ps'].values/100.0\n",
    "\n",
    "xgrid = 96\n",
    "ygrid = 48\n",
    "#length =365*4*2 #1952-7 # 240 for 3 months  #1450 ##338 #160#64#177#1400#455\n",
    "\n",
    "analysis_rmse = np.zeros((length))\n",
    "analysis_rmse_speedy = np.zeros((length))\n",
    "#global_average_ensemble_spread= np.zeros((length))\n",
    "#ps_rmse = np.zeros((length))\n",
    "\n",
    "analysis_error = np.zeros((length,ygrid,xgrid))\n",
    "analysis_error_speedy = np.zeros((length,ygrid,xgrid))\n",
    "\n",
    "print(np.shape(analysis_error))\n",
    "print(np.shape(analysis_error_speedy))\n",
    "for i in range(length):\n",
    "    analysis_rmse[i] = latituded_weighted_rmse(temp_500_nature[i*6,:,:],temp_500_analysis[i,:,:],lats)\n",
    "    analysis_rmse_speedy[i] = latituded_weighted_rmse(temp_500_nature[i*6,:,:],temp_500_analysis_speedy[i,:,:],lats)\n",
    "    #ps_rmse[i] = rms(ps_nature[i*6,:,:],ps_analysis[i,:,:])\n",
    "    analysis_error[i,:,:] = temp_500_analysis[i,:,:] - temp_500_nature[i*6,:,:]\n",
    "    analysis_error_speedy[i,:,:] = temp_500_analysis_speedy[i,:,:] - temp_500_nature[i*6,:,:]\n",
    "    #global_average_ensemble_spread[i] = np.average(temp_500_spread[i,:,:])\n",
    "\n",
    "''' 24(below) instead of 28 to cut transient event (ML spin up) out in first few weeks '''\n",
    "  \n",
    "averaged_error = np.average(abs(analysis_error[24::,:,:]),axis=0)\n",
    "averaged_error_speedy = np.average(abs(analysis_error_speedy[24::,:,:]),axis=0)\n",
    "\n",
    "lat = ds_analysis_mean.lat.values\n",
    "lon = ds_analysis_mean.lon.values\n",
    "\n",
    "lons2d, lats2d = np.meshgrid(lon,lat)\n",
    "\n",
    "fig = plt.figure(figsize=(6,10))\n",
    "''' ax1 ===>  Makes map of hybrid letkf analysis error  '''\n",
    "ax1 = plt.subplot(311,projection=ccrs.PlateCarree())\n",
    "ax1.coastlines()\n",
    "\n",
    "''' Multiply averaged_error by 1000 for spec_humid only'''\n",
    "\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(averaged_error, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "\n",
    "cf = ax1.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(0,10.1,.05),extend='both')\n",
    "plt.colorbar(cf,label='(m/s)')\n",
    "ax1.set_title('Hybrid 1.5,1.3 LETKF Analysis Error\\n 200 hPa Meridional Wind')\n",
    "\n",
    "diff = averaged_error - averaged_error_speedy\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(diff, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "'''ax2 ===>  makes plot of speedy letkf analysis error '''\n",
    "ax2 = plt.subplot(312,projection=ccrs.PlateCarree())\n",
    "ax2.coastlines()\n",
    "\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(averaged_error_speedy, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "\n",
    "cf = ax2.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(0,10.1,.05),extend='both')\n",
    "plt.colorbar(cf,label='(m/s)')\n",
    "ax2.set_title('SPEEDY 1.3 LETKF Analysis Error \\n 200 hPa Meridional Wind')\n",
    "\n",
    "diff = averaged_error - averaged_error_speedy\n",
    "cyclic_data, cyclic_lons = add_cyclic_point(diff, coord=lon)\n",
    "lons2d,lats2d = np.meshgrid(cyclic_lons,lat)\n",
    "\n",
    "'''ax3 ==> Makes map of difference of hybrid and speedy '''\n",
    "\n",
    "ax3 = plt.subplot(313,projection=ccrs.PlateCarree())\n",
    "ax3.coastlines()\n",
    "ax3.set_title('Difference (Hybrid - SPEEDY)')\n",
    "cf = ax3.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(-2,2.1,.01),extend='both',cmap='seismic')\n",
    "\n",
    "#cf = ax3.contourf(lons2d, lats2d,cyclic_data,levels=np.arange(-5,5.1,.5),extend='both',cmap='seismic')\n",
    "plt.colorbar(cf,label='(m/s)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#print('Average RMSE Surface Pressure (hPa)',np.average(ps_rmse))\n",
    "#print('Average RMSE Variable',np.average(ps_rmse))\n",
    "x = np.arange(0,length)\n",
    "\n",
    "base = datetime(1992,1,1,0)\n",
    "plt.figure(figsize=(12,6))\n",
    "date_list = [base + timedelta(days=x/4) for x in range(length)]\n",
    "plt.plot(date_list,analysis_rmse,color='r',linewidth=.15,label='RMSE Hybrid 1.5,1.3') #cov-infl1.3\n",
    "plt.plot(date_list,analysis_rmse_speedy,color='b',linewidth=.15,label='RMSE SPEEDY 1.3')\n",
    "plt.axhline(y=np.average(analysis_rmse[20::]), color='r', linestyle='--',linewidth=1,label=\"Average RMSE Hybrid 1.5,1.3\")\n",
    "plt.axhline(y=np.average(analysis_rmse_speedy[20::]), color='b', linestyle='--',linewidth=1,label=\"Average RMSE SPEEDY 1.3\")\n",
    "print('average rmse Hybrid = ', np.average(analysis_rmse[20::]))\n",
    "print('average rmse SPEEDY = ', np.average(analysis_rmse_speedy[20::]))\n",
    "#plt.plot(date_list,global_average_ensemble_spread,label='Ensemble Spread')\n",
    "#plt.title('LETKF Analysis Error\\n Low Level Specific Humidity')\n",
    "plt.title('LETKF Analysis Error\\n 200 hPa Meridional Wind')\n",
    "#plt.title('Ensemble Spread\\nModel Level 4 Temperature')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Analysis Error')\n",
    "#plt.ylabel('Analysis Error (kg/kg)')\n",
    "#plt.ylabel('Ensemble Spread (K)')\n",
    "plt.xlim([datetime(1992, 1, 1,0), datetime(2003, 2, 1,0)])\n",
    "plt.ylim(3,7)\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "## plot of spin-ups\n",
    "#x= np.arange(0,length)\n",
    "#\n",
    "#date_list = [base + timedelta(days=x/4) for x in range(length)]\n",
    "#plt.plot(date_list,analysis_rmse,color='r',label='RMSE Hybrid ') #cov-infl1.3\n",
    "#plt.plot(date_list,analysis_rmse_speedy,color='b',label='RMSE SPEEDY')\n",
    "#plt.axhline(y=np.average(analysis_rmse[20::]), color='r', linestyle='--',label=\"Average RMSE Hybrid\")\n",
    "#plt.axhline(y=np.average(analysis_rmse_speedy[20::]), color='b', linestyle='--',label=\"Average RMSE SPEEDY\")\n",
    "#print('average rmse Hybrid', np.average(analysis_rmse[20::])) #20\n",
    "#print('average rmse SPEEDY', np.average(analysis_rmse_speedy[20::])) #20\n",
    "##plt.plot(date_list,global_average_ensemble_spread,label='Ensemble Spread')\n",
    "##plt.title('LETKF Analysis Error\\n Low Level Specific Humidity')\n",
    "#plt.title('LETKF Analysis Error\\n 200 hPa Meridional Wind\\n Initial Spin-up')\n",
    "##plt.title('Ensemble Spread\\nModel Level 4 Temperature')\n",
    "#plt.legend()\n",
    "#plt.xlabel('Date')\n",
    "#plt.ylabel('Analysis Error')\n",
    "##plt.ylabel('Analysis Error (kg/kg)')\n",
    "##plt.ylabel('Ensemble Spread (K)')\n",
    "#plt.xlim([datetime(2012, 1, 1,0), datetime(2012, 1, 4,0)])\n",
    "#plt.show()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb048a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,length)\n",
    "\n",
    "base = datetime(1992,1,1,0)\n",
    "plt.figure(figsize=(12,6))\n",
    "date_list = [base + timedelta(days=x/4) for x in range(length)]\n",
    "plt.plot(date_list,analysis_rmse,color='r',linewidth=.15,label='RMSE Hybrid 1.5,1.3') #cov-infl1.3\n",
    "plt.plot(date_list,analysis_rmse_speedy,color='b',linewidth=.15,label='RMSE SPEEDY 1.3')\n",
    "plt.axhline(y=np.average(analysis_rmse[20::]), color='r', linestyle='--',linewidth=1,label=\"Average RMSE Hybrid 1.5,1.3\")\n",
    "plt.axhline(y=np.average(analysis_rmse_speedy[20::]), color='b', linestyle='--',linewidth=1,label=\"Average RMSE SPEEDY 1.3\")\n",
    "print('average rmse Hybrid = ', np.average(analysis_rmse[20::]))\n",
    "print('average rmse SPEEDY = ', np.average(analysis_rmse_speedy[20::]))\n",
    "#plt.plot(date_list,global_average_ensemble_spread,label='Ensemble Spread')\n",
    "#plt.title('LETKF Analysis Error\\n Low Level Specific Humidity')\n",
    "plt.title('LETKF Analysis Error\\n 200 hPa Meridional Wind')\n",
    "#plt.title('Ensemble Spread\\nModel Level 4 Temperature')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Analysis Error')\n",
    "#plt.ylabel('Analysis Error (kg/kg)')\n",
    "#plt.ylabel('Ensemble Spread (K)')\n",
    "plt.xlim([datetime(1992, 1, 1,0), datetime(2003, 2, 1,0)])\n",
    "plt.ylim(3,7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
