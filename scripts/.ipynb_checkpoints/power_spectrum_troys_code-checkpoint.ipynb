{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b35956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116621/1995180336.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "600/18 /4\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3052923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5db4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truth_data(startdate,enddate,var,level,x_slice,y_slice):\n",
    "    target_pressures = [950.0,1000.0]\n",
    "    path = '/skydata2/troyarcomano/ERA_5/'\n",
    "    \n",
    "    hours = enddate - startdate\n",
    "    hours = hours.days * 4 + 1\n",
    "\n",
    "    current_year = startdate.year\n",
    "    end_year = enddate.year\n",
    " \n",
    "    start_index = 0\n",
    "    i = 0\n",
    "    while current_year <=end_year:\n",
    "        file_path = f\"{path}/{current_year}/era_5_y{current_year}_regridded_mpi_fixed_var.nc\"\n",
    "        hours_in_year = dt(current_year,12,31,23) - dt(current_year,1,1,0) \n",
    "        time_slice = slice(0,hours_in_year.days*24 + 1,6)\n",
    "        temp_ds = xr.open_dataset(file_path)\n",
    "        data = temp_ds[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x_slice,Lat=y_slice)\n",
    "        print(data)\n",
    "        print(np.shape(data))\n",
    "        data_ps = temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice)\n",
    "        \n",
    "        if start_index == 0:\n",
    "\n",
    "            #truth_data = np.zeros((hours,np.shape(data)[1],np.shape(data)[2],np.shape(data)[3]))\n",
    "            truth_data = np.zeros((hours,np.shape(data)[0],np.shape(data)[1],np.shape(data)[2]))\n",
    "#             truth_ps = np.zeros((hours,np.shape(data)[2],np.shape(data)[3]))\n",
    "            truth_ps = np.zeros((hours,np.shape(data)[1],np.shape(data)[2]))\n",
    "\n",
    "            temp_climo = np.zeros((11,1460,2,np.shape(data)[2],np.shape(data)[3]))\n",
    "        print('hours_in_year.days*24 + 1',hours_in_year.days*24 + 1)\n",
    "        print('np.shape(data)',data)\n",
    "        print('time_slice',time_slice)\n",
    "        print('np.shape(data)[0]',np.shape(data)[0])\n",
    "        time_length = np.shape(data)[0]\n",
    "        truth_data[start_index:start_index+time_length,:,:] = data.values\n",
    "        truth_ps[start_index:start_index+time_length,:,:] = data_ps.values\n",
    "       \n",
    "        print('start_index,start_index+time_length',start_index,start_index+time_length) \n",
    "  \n",
    "        if(calendar.isleap(current_year)):\n",
    "            time_slice = slice(0,0+240*6,6)\n",
    "            temp_climo[i,0:240,:,:,:] = lin_interp(temp_ds[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x_slice,Lat=y_slice).values,temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice).values,target_pressures)\n",
    "   \n",
    "            time_slice = slice(0+244*6,0+1464*6,6)\n",
    "            temp_climo[i,240:1460,:,:,:] = lin_interp(temp_ds[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x_slice,Lat=y_slice).values,temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice).values,target_pressures)\n",
    "        else:\n",
    "            time_slice = slice(0,0+1460*6,6)\n",
    "            temp_climo[i,:,:,:,:] = lin_interp(temp_ds[var].sel(Lon=x_slice,Lat=y_slice,Sigma_Level=level,Timestep=time_slice).values,temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice).values,target_pressures)\n",
    "   \n",
    "        current_year += 1\n",
    "        i += 1\n",
    "        start_index = start_index + time_length\n",
    "      \n",
    "    return truth_data,truth_ps, temp_climo\n",
    "    \n",
    "\n",
    "\n",
    "def power_spectra_plot(forecast_file,var,level,x,y,speedy_file=None):\n",
    "    time_step = 1/14540\n",
    "    time_slice = slice(1464,17000)\n",
    "    time_slice_truth = slice(1460,17000)\n",
    "    time_slice_speedy = slice(1432,17000)\n",
    "    x = slice(x-5,x+5)\n",
    "    y = slice(y-5,y+5)\n",
    "\n",
    "    startdate = dt(2001,1,1,0)\n",
    "    enddate = dt(2011,12,31,23)\n",
    "    era_data, era_ps, temp_climo = get_truth_data(startdate,enddate,var,level,x,y)\n",
    "\n",
    "    print('np.shape(era_data)',np.shape(era_data))\n",
    "    era_data = lin_interp(era_data,era_ps,[950.0,1000.0])\n",
    "    era_data = era_data[:,0,:,:]\n",
    "\n",
    "    ds_forecast = xr.open_dataset(forecast_file)\n",
    "\n",
    "    forecast_data = ds_forecast[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x,Lat=y)\n",
    "    forecast_ps = ds_forecast['logp'].sel(Timestep=time_slice,Lon=x,Lat=y)\n",
    "   \n",
    "    forecast_data = lin_interp(forecast_data.values,forecast_ps.values,[950.0,1000.0])\n",
    "    forecast_data = forecast_data[:,0,:,:]\n",
    "\n",
    "    if speedy_file:\n",
    "        ds_speedy =  xr.open_dataset(speedy_file)\n",
    "        speedy_data = ds_speedy[var].sel(Timestep=time_slice_speedy,Sigma_Level=level,Lon=x,Lat=y)\n",
    "        speedy_ps = ds_speedy['logp'].sel(Timestep=time_slice_speedy,Lon=x,Lat=y)\n",
    "        speedy_data = lin_interp(speedy_data.values,speedy_ps.values,[950.0,1000.0])\n",
    "        speedy_data = speedy_data[:,0,:,:]\n",
    "\n",
    "\n",
    "    averaged_power_spectrum_era, averaged_power_spectrum_hybrid, averaged_power_spectrum_speedy, freq, idx = average_power_spectrum(era_data,forecast_data,speedy_data=speedy_data)\n",
    "\n",
    "    start_index = dt(2009,12,27,0) - dt(2001,1,1,0)\n",
    "    start_index = start_index.days * 4\n",
    "    end_index = dt(2010,12,27,0) - dt(2001,1,1,0)#startdate\n",
    "    end_index = end_index.days * 4\n",
    "    plot_times_indices_hybrid = np.arange(start_index,end_index)\n",
    "    print('end_index hybrid',end_index)\n",
    "    print(np.shape(forecast_data))\n",
    "\n",
    "    start_index = dt(2009,12,27,0) - dt(2001,1,1,0)\n",
    "    start_index = start_index.days * 4\n",
    "    end_index = dt(2010,12,27,0) - dt(2001,1,1,0)\n",
    "    end_index = end_index.days * 4\n",
    "    plot_times_indices_era = np.arange(start_index,end_index)\n",
    "    \n",
    "    xlabels_cal = ['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec']\n",
    "    xlabels_indices = [0,124,236,360,480,604,724,848,972,1092,1216,1336]\n",
    "\n",
    "    plot_times = np.arange(0,1460)\n",
    "\n",
    "    era_data_plot = np.average(era_data[plot_times_indices_era],axis=(1,2))\n",
    "    forecast_data_plot = np.average(forecast_data[plot_times_indices_hybrid],axis=(1,2)) \n",
    "    speedy_data_plot = np.average(speedy_data[plot_times_indices_hybrid],axis=(1,2))\n",
    "\n",
    "    era_data_mean = np.average(temp_climo[:,:,0,:,:]-273.15,axis=(0,2,3))\n",
    "    era_data_sd = np.std(temp_climo[:,:,0,:,:]-273.15,axis=(0,2,3))\n",
    "\n",
    "\n",
    "    upper_2sd_range = era_data_mean+era_data_sd*2\n",
    "    lower_2sd_range = era_data_mean-era_data_sd*2 \n",
    "\n",
    "    hybrid_out = outside_range(np.average(forecast_data,axis=(1,2)),dt(2001,1,1,0),dt(2010,12,31,23),upper_2sd_range,lower_2sd_range)\n",
    "    speedy_out = outside_range(np.average(speedy_data,axis=(1,2)),dt(2001,1,1,0),dt(2010,12,31,23),upper_2sd_range,lower_2sd_range)\n",
    "\n",
    "    print('Percent outside 2 SD hybrid',hybrid_out)\n",
    "    print('Percent outside 2 SD SPEEDY',speedy_out)\n",
    "    fig, axes = plt.subplots(3,1,figsize=(15,10),constrained_layout=True)\n",
    "\n",
    "    ### \n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title('Power Spectrum',fontsize=18,fontweight=\"bold\")\n",
    "    ax1.loglog(freq[idx],averaged_power_spectrum_era[idx],label='ERA 5',color='#e41a1c')#,zorder=10)\n",
    "    ax1.loglog(freq[idx],averaged_power_spectrum_hybrid[idx],label='Hybrid',color='#377eb8',zorder=10)\n",
    "\n",
    "    ax1.legend(fontsize=18)\n",
    "   \n",
    "    print('np.max(freq[idx])',np.max(freq[idx]))\n",
    "    print('daily power era',averaged_power_spectrum_era[np.where(freq == 1.0)])\n",
    "    print('daily power hybrid',averaged_power_spectrum_hybrid[np.where(freq == 1.0)])\n",
    "    print('diff power',averaged_power_spectrum_era[np.where(freq == 1.0)]-averaged_power_spectrum_hybrid[np.where(freq == 1.0)])\n",
    "    ax1.set_xlim(1/(5*365.0),2.01) \n",
    "    ax1.set_ylim(np.min([np.min(averaged_power_spectrum_speedy[idx]),np.min(averaged_power_spectrum_era[idx])]),2*10**10)#np.max([np.max(averaged_power_spectrum_hybrid[idx]),np.max(averaged_power_spectrum_era[idx])]))\n",
    "    ax1.minorticks_off()\n",
    "    ax1.set_ylabel('$[Kelvin]^2$',fontsize=18)\n",
    "\n",
    "    ax1.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off'  # labels along the bottom edge are off)\n",
    "        )\n",
    "\n",
    "    for tic in ax1.xaxis.get_major_ticks():\n",
    "        tic.tick1On = tic.tick2On = False\n",
    "        tic.label1On = tic.label2On = False\n",
    "    ax1.grid() \n",
    "\n",
    "\n",
    "    ###\n",
    "    ax2 = axes[1]\n",
    "    ax2.sharex(ax1)\n",
    "    ax2.sharex(ax1)\n",
    "    #ax2.loglog(freq[idx],averaged_power_spectrum_hybrid[idx],label='Hybrid',color='#377eb8') \n",
    "    ax2.loglog(freq[idx],averaged_power_spectrum_era[idx],label='ERA 5',color='#e41a1c')#,zorder=10)\n",
    "    if speedy_file:\n",
    "        ax2.semilogy(freq[idx],averaged_power_spectrum_speedy[idx],label='SPEEDY',color='#4daf4a',zorder=10)\n",
    "\n",
    "    ax2.legend(fontsize=18)\n",
    "\n",
    "    xlabels_indices = [10**-3,1/365.0,10**-2,1/30.0,10**-1,1/7.0,1,2]\n",
    "    xlabels_cal = [r'$10^{-3}$','Annual',r'$10^{-2}$','Monthly',r'$10^{-1}$','Weekly','Daily','12 hrs']\n",
    "    ax2.set_xticks(xlabels_indices)\n",
    "    ax2.set_xticklabels(xlabels_cal,fontsize=16,rotation = 45)\n",
    "    ax2.set_xlim(1/(5*365.0),2.01)#np.min(freq[idx]),2.01)\n",
    "    ax2.set_ylim(np.min([np.min(averaged_power_spectrum_speedy[idx]),np.min(averaged_power_spectrum_era[idx])]),2*10**10)\n",
    "    ax2.grid()\n",
    "    ax2.minorticks_off()\n",
    "    ax2.set_ylabel('$[Kelvin]^2$',fontsize=18)\n",
    "    ax2.set_xlabel('Frequency (1/day)',fontsize=18)\n",
    "\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "\n",
    "\n",
    "    xlabels_cal = ['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec']\n",
    "    xlabels_indices = [0,124,236,360,480,604,724,848,972,1092,1216,1336]\n",
    "\n",
    "    ax = axes[2]\n",
    "    ax.set_title('950 hPa Temperature',fontsize=18,fontweight=\"bold\")\n",
    "    ax.plot(plot_times,forecast_data_plot - 273.15,label='Hybrid',color='#377eb8')\n",
    "\n",
    "    #sd_1 = ax.fill_between(plot_times,era_data_mean+era_data_sd,era_data_mean-era_data_sd, facecolor='grey', alpha=0.4)\n",
    "    sd_2 = ax.fill_between(plot_times,era_data_mean+era_data_sd*2,era_data_mean-era_data_sd*2, facecolor='grey', alpha=0.4)\n",
    "\n",
    "    if speedy_file:\n",
    "        ax.plot(plot_times,speedy_data_plot - 273.15,label='SPEEDY',color='#4daf4a',linewidth=3)\n",
    "    l1 = ax.legend(fontsize=14,loc=1)\n",
    "    l2 = ax.legend([sd_2],['2 Sigma Range'],fontsize=14,loc=8)\n",
    "    ax.add_artist(l1)\n",
    "    ax.set_xticks(xlabels_indices)\n",
    "    ax.set_yticks(np.arange(5,45,5))\n",
    "    ax.set_yticklabels(np.arange(5,45,5),fontsize=14) \n",
    "    ax.set_xticklabels(xlabels_cal,fontsize=16,rotation = 45)\n",
    "    ax.set_ylabel('Celsius',fontsize=18)\n",
    "    ax.set_xlim(0,1460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca8fa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_power_spectrum(era_data,forecast_data,speedy_data=None):\n",
    "    time_step = 1/4.0#1/14540\n",
    "    power_spectra_era = np.zeros((14540,np.shape(era_data)[1],np.shape(era_data)[2]))\n",
    "    power_spectra_forecast = np.zeros((14540,np.shape(era_data)[1],np.shape(era_data)[2]))\n",
    "    power_spectra_speedy = np.zeros((14540,np.shape(era_data)[1],np.shape(era_data)[2]))\n",
    "\n",
    "    hamming = np.hanning(14540)\n",
    "    for i in range(np.shape(era_data)[1]):\n",
    "        for j in range(np.shape(era_data)[2]):\n",
    "\n",
    "            fft_era = np.fft.fft(era_data[0:14540,i,j]*hamming)\n",
    "            fft_forecast = np.fft.fft(forecast_data[0:14540,i,j]*hamming)\n",
    "\n",
    "            power_spectra_era[:,i,j] = np.abs(fft_era)**2.0\n",
    "            power_spectra_forecast[:,i,j]= np.abs(fft_forecast)**2.0\n",
    "\n",
    "            if speedy_data is not None:\n",
    "                fft_speedy = np.fft.fft(speedy_data[0:14540,i,j]*hamming)\n",
    "                power_spectra_speedy[:,i,j] = np.abs(fft_speedy)**2.0\n",
    "\n",
    "            print(np.shape(power_spectra_speedy),'power_spectra_speedy shape')\n",
    "            freq = np.fft.fftfreq(len(speedy_data[0:14540,i,j]),time_step)\n",
    "\n",
    "            idx = np.argsort(freq)\n",
    "            idx = idx[int(len(idx)/2)::]\n",
    "\n",
    "           #freq = 4*(freq/14540)\n",
    "\n",
    "    averaged_power_spectrum_era = np.average(power_spectra_era,axis=(1,2))\n",
    "    averaged_power_spectrum_hybrid = np.average(power_spectra_forecast,axis=(1,2))\n",
    "    averaged_power_spectrum_speedy = np.average(power_spectra_speedy,axis=(1,2))\n",
    "\n",
    "    return averaged_power_spectrum_era, averaged_power_spectrum_hybrid, averaged_power_spectrum_speedy, freq, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb0512bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hybrid 1.9,1.9\n",
    "hybrid_1_9_1_9_file = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/hybrid_1_9_1_9_mem_1_fixed_20110101_20120115/out.nc'\n",
    "\n",
    "#speedy 1.9\n",
    "speedy_1_9_file = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/speedy_1_9_uniform_20110101_20110501/mean.nc'\n",
    "\n",
    "#era5 trained 1.9\n",
    "era_5_1_9_file = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/ERA5_1_9/mean_output/out.nc'\n",
    "\n",
    "#hybrid from grace \n",
    "hybrid_1_9_1_9_128_procs_file = '/skydata2/dylanelliott/letkf-hybrid-speedy/DATA/uniform_letkf_anal/hybrid_1_9_1_9_test_128_procs_from_grace/mean_output/out.nc'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa3fa1ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'Temperature' (Timestep: 1457, Lat: 3, Lon: 3)>\n",
      "array([[[295.42276, 295.26392, 295.9063 ],\n",
      "        [298.43976, 295.7406 , 296.9338 ],\n",
      "        [294.73087, 293.48047, 294.61084]],\n",
      "\n",
      "       [[293.47925, 292.62726, 293.70084],\n",
      "        [296.61487, 294.53842, 295.82834],\n",
      "        [292.82852, 291.96344, 293.31876]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[298.55957, 301.0833 , 300.81763],\n",
      "        [301.1038 , 298.7309 , 298.94977],\n",
      "        [297.63043, 295.92297, 296.6525 ]],\n",
      "\n",
      "       [[295.87872, 296.9123 , 296.2131 ],\n",
      "        [299.39777, 296.54675, 297.34766],\n",
      "        [294.6876 , 293.49554, 292.43997]]], dtype=float32)\n",
      "Coordinates:\n",
      "  * Lon      (Lon) float32 7.5 11.25 15.0\n",
      "  * Lat      (Lat) float32 5.567 9.278 12.99\n",
      "Dimensions without coordinates: Timestep\n",
      "Attributes:\n",
      "    units:    Kelvin\n",
      "(1457, 3, 3)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpower_spectra_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhybrid_1_9_1_9_file\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mspeedy_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 69\u001b[0m, in \u001b[0;36mpower_spectra_plot\u001b[0;34m(forecast_file, var, level, x, y, speedy_file)\u001b[0m\n\u001b[1;32m     67\u001b[0m startdate \u001b[38;5;241m=\u001b[39m dt(\u001b[38;5;241m2001\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     68\u001b[0m enddate \u001b[38;5;241m=\u001b[39m dt(\u001b[38;5;241m2011\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m31\u001b[39m,\u001b[38;5;241m23\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m era_data, era_ps, temp_climo \u001b[38;5;241m=\u001b[39m \u001b[43mget_truth_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43menddate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnp.shape(era_data)\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mshape(era_data))\n\u001b[1;32m     72\u001b[0m era_data \u001b[38;5;241m=\u001b[39m lin_interp(era_data,era_ps,[\u001b[38;5;241m950.0\u001b[39m,\u001b[38;5;241m1000.0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m, in \u001b[0;36mget_truth_data\u001b[0;34m(startdate, enddate, var, level, x_slice, y_slice)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#             truth_ps = np.zeros((hours,np.shape(data)[2],np.shape(data)[3]))\u001b[39;00m\n\u001b[1;32m     28\u001b[0m             truth_ps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((hours,np\u001b[38;5;241m.\u001b[39mshape(data)[\u001b[38;5;241m1\u001b[39m],np\u001b[38;5;241m.\u001b[39mshape(data)[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m---> 30\u001b[0m             temp_climo \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m1460\u001b[39m,\u001b[38;5;241m2\u001b[39m,np\u001b[38;5;241m.\u001b[39mshape(data)[\u001b[38;5;241m2\u001b[39m],\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhours_in_year.days*24 + 1\u001b[39m\u001b[38;5;124m'\u001b[39m,hours_in_year\u001b[38;5;241m.\u001b[39mdays\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m24\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnp.shape(data)\u001b[39m\u001b[38;5;124m'\u001b[39m,data)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "x=10\n",
    "y=10\n",
    "power_spectra_plot(hybrid_1_9_1_9_file,'Temperature',7,x,y,speedy_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c92e01d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1193312570.py, line 383)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 383\u001b[0;36m\u001b[0m\n\u001b[0;31m    >>>>>>> d99de237d7ae50a46d3057bab2d46a581b28c3a8\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from netCDF4 import Dataset\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import xarray as xr\n",
    "import glob\n",
    "from datetime import datetime as dt\n",
    "from numba import jit\n",
    "from scipy import signal\n",
    "import calendar\n",
    "\n",
    "@jit(nopython=True,fastmath=True)\n",
    "def lin_interp(var,ps,target_pressures):\n",
    "    speedy_sigma = np.array([0.025, 0.095, 0.20, 0.34, 0.51, 0.685, 0.835, 0.95])\n",
    "\n",
    "    #var = np.asarray(var)\n",
    "\n",
    "    ps = np.exp(ps) * 1000.0\n",
    "\n",
    "    ygrid = np.shape(var)[2]\n",
    "    xgrid = np.shape(var)[3]\n",
    "\n",
    "    time_length = np.shape(ps)[0]\n",
    "\n",
    "    var_pressure = np.zeros((time_length,len(speedy_sigma),ygrid,xgrid))\n",
    "\n",
    "    for t in range(time_length):\n",
    "        for i in range(len(speedy_sigma)):\n",
    "            var_pressure[t,i,:,:] = speedy_sigma[i] * ps[t,:,:]\n",
    "\n",
    "\n",
    "    regridded_data = np.zeros((time_length,len(target_pressures),ygrid,xgrid))\n",
    "\n",
    "    for t in range(time_length):\n",
    "        for i in range(ygrid):\n",
    "            for j in range(xgrid): \n",
    "                regridded_data[t,:,i,j] = np.interp(target_pressures,var_pressure[t,:,i,j],var[t,:,i,j])\n",
    "\n",
    "    return regridded_data\n",
    "\n",
    "def get_files(path,pattern):\n",
    "    files = glob.glob(path+pattern)\n",
    "    return files\n",
    "\n",
    "def get_speedy_files(truthfiles):\n",
    "    #speedy_data_dir = '/scratch/user/troyarcomano/FortranReservoir/speedyintegration/parallel_prediction_data/speedy_data/'\n",
    "    speedy_data_dir = '/scratch/user/troyarcomano/temp_storage/'\n",
    "    speedyfiles = list()\n",
    "    for i in range(len(truthfiles)):\n",
    "        truthfile = truthfiles[i]\n",
    "        endfile = truthfile[-16:-3]\n",
    "        #pattern = \"speedy_era_start\"+\"*\"+endfile+\"*.nc\"\n",
    "        pattern = \"speedy_\"+\"*\"+endfile+\"*.nc\"\n",
    "        try:\n",
    "           speedyfiles.append(get_files(speedy_data_dir,pattern)[0])\n",
    "        except:\n",
    "           print('skipping this',pattern)\n",
    "\n",
    "    return speedyfiles\n",
    "\n",
    "def get_truth_data(startdate,enddate,var,level,x_slice,y_slice):\n",
    "    target_pressures = [950.0,1000.0]\n",
    "    path = '/scratch/user/troyarcomano/ERA_5/'\n",
    "    \n",
    "    hours = enddate - startdate\n",
    "    hours = hours.days * 4 + 1\n",
    "\n",
    "    current_year = startdate.year\n",
    "    end_year = enddate.year\n",
    " \n",
    "    start_index = 0\n",
    "    i = 0\n",
    "    while current_year <=end_year:\n",
    "      file_path = f\"{path}/{current_year}/era_5_y{current_year}_regridded_mpi_fixed_var.nc\"\n",
    "      hours_in_year = dt(current_year,12,31,23) - dt(current_year,1,1,0) \n",
    "      time_slice = slice(0,hours_in_year.days*24 + 1,6)\n",
    "      temp_ds = xr.open_dataset(file_path)\n",
    "      data = temp_ds[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x_slice,Lat=y_slice)\n",
    "      data_ps = temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice)\n",
    "      if start_index == 0:\n",
    "         truth_data = np.zeros((hours,np.shape(data)[1],np.shape(data)[2],np.shape(data)[3]))\n",
    "         truth_ps = np.zeros((hours,np.shape(data)[2],np.shape(data)[3]))\n",
    "         temp_climo = np.zeros((11,1460,2,np.shape(data)[2],np.shape(data)[3]))\n",
    "      print('hours_in_year.days*24 + 1',hours_in_year.days*24 + 1)\n",
    "      print('np.shape(data)',data)\n",
    "      print('time_slice',time_slice)\n",
    "      print('np.shape(data)[0]',np.shape(data)[0])\n",
    "      time_length = np.shape(data)[0]\n",
    "      truth_data[start_index:start_index+time_length,:,:] = data.values\n",
    "      truth_ps[start_index:start_index+time_length,:,:] = data_ps.values\n",
    "     \n",
    "      print('start_index,start_index+time_length',start_index,start_index+time_length) \n",
    "\n",
    "      if(calendar.isleap(current_year)):\n",
    "         time_slice = slice(0,0+240*6,6)\n",
    "         temp_climo[i,0:240,:,:,:] = lin_interp(temp_ds[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x_slice,Lat=y_slice).values,temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice).values,target_pressures)\n",
    "\n",
    "         time_slice = slice(0+244*6,0+1464*6,6)\n",
    "         temp_climo[i,240:1460,:,:,:] = lin_interp(temp_ds[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x_slice,Lat=y_slice).values,temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice).values,target_pressures)\n",
    "      else:\n",
    "         time_slice = slice(0,0+1460*6,6)\n",
    "         temp_climo[i,:,:,:,:] = lin_interp(temp_ds[var].sel(Lon=x_slice,Lat=y_slice,Sigma_Level=level,Timestep=time_slice).values,temp_ds['logp'].sel(Timestep=time_slice,Lon=x_slice,Lat=y_slice).values,target_pressures)\n",
    "\n",
    "      current_year += 1\n",
    "      i += 1\n",
    "      start_index = start_index + time_length\n",
    "      \n",
    "    return truth_data,truth_ps, temp_climo\n",
    "    \n",
    "12:14\n",
    "@jit() \n",
    "def average_power_spectrum(era_data,forecast_data,speedy_data=None):\n",
    "    time_step = 1/4.0#1/14540\n",
    "    power_spectra_era = np.zeros((14540,np.shape(era_data)[1],np.shape(era_data)[2]))\n",
    "    power_spectra_forecast = np.zeros((14540,np.shape(era_data)[1],np.shape(era_data)[2]))\n",
    "    power_spectra_speedy = np.zeros((14540,np.shape(era_data)[1],np.shape(era_data)[2]))\n",
    "\n",
    "    hamming = np.hanning(14540)\n",
    "    for i in range(np.shape(era_data)[1]):\n",
    "        for j in range(np.shape(era_data)[2]):\n",
    "\n",
    "           fft_era = np.fft.fft(era_data[0:14540,i,j]*hamming)\n",
    "           fft_forecast = np.fft.fft(forecast_data[0:14540,i,j]*hamming)\n",
    "\n",
    "           power_spectra_era[:,i,j] = np.abs(fft_era)**2.0\n",
    "           power_spectra_forecast[:,i,j]= np.abs(fft_forecast)**2.0\n",
    "\n",
    "           if speedy_data is not None:\n",
    "              fft_speedy = np.fft.fft(speedy_data[0:14540,i,j]*hamming)\n",
    "              power_spectra_speedy[:,i,j] = np.abs(fft_speedy)**2.0\n",
    "\n",
    "           print(np.shape(power_spectra_speedy),'power_spectra_speedy shape')\n",
    "           freq = np.fft.fftfreq(len(speedy_data[0:14540,i,j]),time_step)\n",
    "\n",
    "           idx = np.argsort(freq)\n",
    "           idx = idx[int(len(idx)/2)::]\n",
    "\n",
    "           #freq = 4*(freq/14540)\n",
    "\n",
    "    averaged_power_spectrum_era = np.average(power_spectra_era,axis=(1,2))\n",
    "    averaged_power_spectrum_hybrid = np.average(power_spectra_forecast,axis=(1,2))\n",
    "    averaged_power_spectrum_speedy = np.average(power_spectra_speedy,axis=(1,2))\n",
    "\n",
    "    return averaged_power_spectrum_era, averaged_power_spectrum_hybrid, averaged_power_spectrum_speedy, freq, idx\n",
    "\n",
    "def outside_range(data,startdate,enddate,upper_2sd_range,lower_2sd_range):\n",
    "\n",
    "    current_year = startdate.year\n",
    "    end_year = enddate.year\n",
    "\n",
    "    start_index = 0\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    while current_year <=end_year: \n",
    "       hours_in_year = dt(current_year,12,31,23) - dt(current_year,1,1,0)\n",
    "\n",
    "       if(calendar.isleap(current_year)): \n",
    "          print(current_year)\n",
    "          upper_data_diff = (data[start_index:start_index+240]-273.15) - upper_2sd_range[0:240]\n",
    "          lower_data_diff = (data[start_index:start_index+240]-273.15) - lower_2sd_range[0:240]\n",
    "          \n",
    "          counter = counter + np.sum(upper_data_diff> 0.0)+np.sum(lower_data_diff < 0.0)\n",
    "  \n",
    "          upper_data_diff = (data[start_index+244:start_index+1464]-273.15) - upper_2sd_range[240:1460]\n",
    "          lower_data_diff = (data[start_index+244:start_index+1464]-273.15) - lower_2sd_range[240:1460] \n",
    "\n",
    "          counter = counter + np.sum(upper_data_diff> 0.0)+np.sum(lower_data_diff < 0.0)\n",
    "       else:\n",
    "          upper_data_diff = (data[start_index:start_index+1460]-273.15) - upper_2sd_range\n",
    "          lower_data_diff = (data[start_index:start_index+1460]-273.15) - lower_2sd_range\n",
    "\n",
    "          counter = counter + np.sum(upper_data_diff > 0.0)+np.sum(lower_data_diff < 0.0)\n",
    "           \n",
    "       current_year += 1\n",
    "       i += 1\n",
    "       start_index = start_index + hours_in_year.days*4\n",
    "\n",
    "    return (counter/np.shape(data)[0])*100.0\n",
    "\n",
    "def power_spectra_plot(forecast_file,var,level,x,y,speedy_file=None):\n",
    "    time_step = 1/14540\n",
    "    time_slice = slice(1464,17000)\n",
    "    time_slice_truth = slice(1460,17000)\n",
    "    time_slice_speedy = slice(1432,17000)\n",
    "    x = slice(x-5,x+5)\n",
    "    y = slice(y-5,y+5)\n",
    "\n",
    "    startdate = dt(2001,1,1,0)\n",
    "    enddate = dt(2011,12,31,23)\n",
    "    era_data, era_ps, temp_climo = get_truth_data(startdate,enddate,var,level,x,y)\n",
    "\n",
    "    print('np.shape(era_data)',np.shape(era_data))\n",
    "    era_data = lin_interp(era_data,era_ps,[950.0,1000.0])\n",
    "    era_data = era_data[:,0,:,:]\n",
    "\n",
    "    ds_forecast = xr.open_dataset(forecast_file)\n",
    "\n",
    "    forecast_data = ds_forecast[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x,Lat=y)\n",
    "    forecast_ps = ds_forecast['logp'].sel(Timestep=time_slice,Lon=x,Lat=y)\n",
    "   \n",
    "    forecast_data = lin_interp(forecast_data.values,forecast_ps.values,[950.0,1000.0])\n",
    "    forecast_data = forecast_data[:,0,:,:]\n",
    "\n",
    "    if speedy_file:\n",
    "       ds_speedy =  xr.open_dataset(speedy_file)\n",
    "       speedy_data = ds_speedy[var].sel(Timestep=time_slice_speedy,Sigma_Level=level,Lon=x,Lat=y)\n",
    "       speedy_ps = ds_speedy['logp'].sel(Timestep=time_slice_speedy,Lon=x,Lat=y)\n",
    "       speedy_data = lin_interp(speedy_data.values,speedy_ps.values,[950.0,1000.0])\n",
    "       speedy_data = speedy_data[:,0,:,:]\n",
    "\n",
    "\n",
    "    averaged_power_spectrum_era, averaged_power_spectrum_hybrid, averaged_power_spectrum_speedy, freq, idx = average_power_spectrum(era_data,forecast_data,speedy_data=speedy_data)\n",
    "\n",
    "    start_index = dt(2009,12,27,0) - dt(2001,1,1,0)\n",
    "    start_index = start_index.days * 4\n",
    "    end_index = dt(2010,12,27,0) - dt(2001,1,1,0)#startdate\n",
    "    end_index = end_index.days * 4\n",
    "    plot_times_indices_hybrid = np.arange(start_index,end_index)\n",
    "    print('end_index hybrid',end_index)\n",
    "    print(np.shape(forecast_data))\n",
    "\n",
    "    start_index = dt(2009,12,27,0) - dt(2001,1,1,0)\n",
    "    start_index = start_index.days * 4\n",
    "    end_index = dt(2010,12,27,0) - dt(2001,1,1,0)\n",
    "    end_index = end_index.days * 4\n",
    "    plot_times_indices_era = np.arange(start_index,end_index)\n",
    "    \n",
    "    xlabels_cal = ['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec']\n",
    "    xlabels_indices = [0,124,236,360,480,604,724,848,972,1092,1216,1336]\n",
    "\n",
    "    plot_times = np.arange(0,1460)\n",
    "\n",
    "    era_data_plot = np.average(era_data[plot_times_indices_era],axis=(1,2))\n",
    "    forecast_data_plot = np.average(forecast_data[plot_times_indices_hybrid],axis=(1,2)) \n",
    "    speedy_data_plot = np.average(speedy_data[plot_times_indices_hybrid],axis=(1,2))\n",
    "\n",
    "    era_data_mean = np.average(temp_climo[:,:,0,:,:]-273.15,axis=(0,2,3))\n",
    "    era_data_sd = np.std(temp_climo[:,:,0,:,:]-273.15,axis=(0,2,3))\n",
    "\n",
    "\n",
    "    upper_2sd_range = era_data_mean+era_data_sd*2\n",
    "    lower_2sd_range = era_data_mean-era_data_sd*2 \n",
    "\n",
    "    hybrid_out = outside_range(np.average(forecast_data,axis=(1,2)),dt(2001,1,1,0),dt(2010,12,31,23),upper_2sd_range,lower_2sd_range)\n",
    "    speedy_out = outside_range(np.average(speedy_data,axis=(1,2)),dt(2001,1,1,0),dt(2010,12,31,23),upper_2sd_range,lower_2sd_range)\n",
    "\n",
    "    print('Percent outside 2 SD hybrid',hybrid_out)\n",
    "    print('Percent outside 2 SD SPEEDY',speedy_out)\n",
    "    fig, axes = plt.subplots(3,1,figsize=(15,10),constrained_layout=True)\n",
    "\n",
    "    ### \n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title('Power Spectrum',fontsize=18,fontweight=\"bold\")\n",
    "    ax1.loglog(freq[idx],averaged_power_spectrum_era[idx],label='ERA 5',color='#e41a1c')#,zorder=10)\n",
    "    ax1.loglog(freq[idx],averaged_power_spectrum_hybrid[idx],label='Hybrid',color='#377eb8',zorder=10)\n",
    "\n",
    "    ax1.legend(fontsize=18)\n",
    "   \n",
    "    print('np.max(freq[idx])',np.max(freq[idx]))\n",
    "    print('daily power era',averaged_power_spectrum_era[np.where(freq == 1.0)])\n",
    "    print('daily power hybrid',averaged_power_spectrum_hybrid[np.where(freq == 1.0)])\n",
    "    print('diff power',averaged_power_spectrum_era[np.where(freq == 1.0)]-averaged_power_spectrum_hybrid[np.where(freq == 1.0)])\n",
    "    ax1.set_xlim(1/(5*365.0),2.01) \n",
    "    ax1.set_ylim(np.min([np.min(averaged_power_spectrum_speedy[idx]),np.min(averaged_power_spectrum_era[idx])]),2*10**10)#np.max([np.max(averaged_power_spectrum_hybrid[idx]),np.max(averaged_power_spectrum_era[idx])]))\n",
    "    ax1.minorticks_off()\n",
    "    ax1.set_ylabel('$[Kelvin]^2$',fontsize=18)\n",
    "\n",
    "    ax1.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off'  # labels along the bottom edge are off)\n",
    "        )\n",
    "\n",
    "    for tic in ax1.xaxis.get_major_ticks():\n",
    "        tic.tick1On = tic.tick2On = False\n",
    "        tic.label1On = tic.label2On = False\n",
    "    ax1.grid() \n",
    "\n",
    "\n",
    "    ###\n",
    "    ax2 = axes[1]\n",
    "    ax2.sharex(ax1)\n",
    "    ax2.sharex(ax1)\n",
    "    #ax2.loglog(freq[idx],averaged_power_spectrum_hybrid[idx],label='Hybrid',color='#377eb8') \n",
    "    ax2.loglog(freq[idx],averaged_power_spectrum_era[idx],label='ERA 5',color='#e41a1c')#,zorder=10)\n",
    "    if speedy_file:\n",
    "       ax2.semilogy(freq[idx],averaged_power_spectrum_speedy[idx],label='SPEEDY',color='#4daf4a',zorder=10)\n",
    "\n",
    "    ax2.legend(fontsize=18)\n",
    "\n",
    "    xlabels_indices = [10**-3,1/365.0,10**-2,1/30.0,10**-1,1/7.0,1,2]\n",
    "    xlabels_cal = [r'$10^{-3}$','Annual',r'$10^{-2}$','Monthly',r'$10^{-1}$','Weekly','Daily','12 hrs']\n",
    "    ax2.set_xticks(xlabels_indices)\n",
    "    ax2.set_xticklabels(xlabels_cal,fontsize=16,rotation = 45)\n",
    "    ax2.set_xlim(1/(5*365.0),2.01)#np.min(freq[idx]),2.01)\n",
    "    ax2.set_ylim(np.min([np.min(averaged_power_spectrum_speedy[idx]),np.min(averaged_power_spectrum_era[idx])]),2*10**10)\n",
    "    ax2.grid()\n",
    "    ax2.minorticks_off()\n",
    "    ax2.set_ylabel('$[Kelvin]^2$',fontsize=18)\n",
    "    ax2.set_xlabel('Frequency (1/day)',fontsize=18)\n",
    "\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "\n",
    "\n",
    "    xlabels_cal = ['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec']\n",
    "    xlabels_indices = [0,124,236,360,480,604,724,848,972,1092,1216,1336]\n",
    "\n",
    "    ax = axes[2]\n",
    "    ax.set_title('950 hPa Temperature',fontsize=18,fontweight=\"bold\")\n",
    "    ax.plot(plot_times,forecast_data_plot - 273.15,label='Hybrid',color='#377eb8')\n",
    "\n",
    "    #sd_1 = ax.fill_between(plot_times,era_data_mean+era_data_sd,era_data_mean-era_data_sd, facecolor='grey', alpha=0.4)\n",
    "    sd_2 = ax.fill_between(plot_times,era_data_mean+era_data_sd*2,era_data_mean-era_data_sd*2, facecolor='grey', alpha=0.4)\n",
    "\n",
    "    if speedy_file:\n",
    "       ax.plot(plot_times,speedy_data_plot - 273.15,label='SPEEDY',color='#4daf4a',linewidth=3)\n",
    "    l1 = ax.legend(fontsize=14,loc=1)\n",
    "    l2 = ax.legend([sd_2],['2 Sigma Range'],fontsize=14,loc=8)\n",
    "    ax.add_artist(l1)\n",
    "    ax.set_xticks(xlabels_indices)\n",
    "    ax.set_yticks(np.arange(5,45,5))\n",
    "    ax.set_yticklabels(np.arange(5,45,5),fontsize=14)\n",
    "    ax.set_xticklabels(xlabels_cal,fontsize=16,rotation = 45)\n",
    "    ax.set_ylabel('Celsius',fontsize=18)\n",
    "    ax.set_xlim(0,1460)\n",
    "\n",
    "\n",
    "def power_spectra(forecast_file,truth_file,var,level,x,y,speedy_file=None):\n",
    "    print(forecast_file,truth_file,speedy_file)\n",
    "    time_step = 1/14540\n",
    "    time_slice = slice(1460,16000)\n",
    "    time_slice_truth = slice(1460,16000)\n",
    "    time_slice_speedy = slice(1460,16000)\n",
    "    x = slice(x-2,x+2)\n",
    "    y = slice(y-2,y+2)\n",
    "\n",
    "    ds_era = xr.open_dataset(truth_file)\n",
    "    ds_forecast = xr.open_dataset(forecast_file)\n",
    "\n",
    "    print(ds_era.Lat)\n",
    "\n",
    "    era_data = np.squeeze(ds_era[var].sel(Timestep=time_slice_truth,Sigma_Level=level,Lon=x,Lat=y))\n",
    "    forecast_data = np.squeeze(ds_forecast[var].sel(Timestep=time_slice,Sigma_Level=level,Lon=x,Lat=y))\n",
    " \n",
    "    if speedy_file:\n",
    "       ds_speedy =  xr.open_dataset(speedy_file)\n",
    "       speedy_data = np.squeeze(ds_speedy[var].sel(Timestep=time_slice_speedy,Sigma_Level=level,Lon=x,Lat=y))\n",
    " \n",
    "    plt.plot(era_data,label='Truth')\n",
    "    plt.plot(forecast_data,label='Hybrid')\n",
    "\n",
    "    if speedy_file:\n",
    "       plt.plot(speedy_data,label='SPEEDY')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "   \n",
    "    fft_era = np.fft.fft(era_data)\n",
    "    fft_forecast = np.fft.fft(forecast_data)\n",
    "\n",
    "    power_spectra_era = np.abs(fft_era)**2.0\n",
    "    power_spectra_forecast= np.abs(fft_forecast)**2.0\n",
    "\n",
    "    if speedy_file:\n",
    "       fft_speedy = np.fft.fft(speedy_data)\n",
    "       power_spectra_speedy = np.abs(fft_speedy)**2.0\n",
    "\n",
    "    freq = np.fft.fftfreq(len(era_data),time_step) \n",
    "\n",
    "    idx = np.argsort(freq)\n",
    "    idx = idx[int(len(idx)/2):-1]\n",
    "\n",
    "    freq = 4*(freq/14540)\n",
    "    plt.loglog(freq[idx],power_spectra_era[idx])\n",
    "    plt.loglog(freq[idx],power_spectra_forecast[idx])\n",
    "    if speedy_file:\n",
    "       plt.semilogy(freq[idx],power_spectra_speedy[idx])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "trialname = '6000_20_20_20_beta_res0.1_beta_model_0.01_prior_0.0_overlap1_era5_6hrtimestep_21yearsnontruncated_data_year_long_forecaststrial'\n",
    "#trialname  = '6000_25_25_25_beta_res0.0001_beta_model_0.001_10_noise_modeltrial'\n",
    "\n",
    "#trialname_parallel = '9000node_28_28_28_noise_beta_0.00001_degree6_cylcing12hr_sigma0.5_radius0.3_0.7_long_prediction_year_simulationtrial'\n",
    "trialname_parallel = '9000node_28_28_28_noise_beta_0.001_1hrtimestep_full_datatrial'\n",
    "\n",
    "xlimit_array = [[0,10.0],[0,25.0],[0,2.0]]\n",
    "12:14\n",
    "truth_pattern = f'era_truth{trialname}*.nc'\n",
    "hybrid_pattern = f'hybrid_prediction_era{trialname}*.nc'\n",
    "#parallel_pattern = f'res_prediction_era{trialname_parallel}'\n",
    "parallel_pattern = f'res_prediction_era{trialname_parallel}*.nc'\n",
    "parallel_truth_pattern = f'era_truth{trialname_parallel}*.nc'\n",
    "\n",
    "path = '/scratch/user/troyarcomano/Predictions/Hybrid/'\n",
    "#path = '/tiered/user/troyarcomano/hybrid_prediction_data/'\n",
    "\n",
    "truth_files = get_files(path,truth_pattern)\n",
    "hybrid_files = get_files(path,hybrid_pattern)\n",
    "speedy_files = get_speedy_files(sorted(truth_files))\n",
    "\n",
    "#parallel_files = get_parallel_files(truth_files,parallel_pattern)\n",
    "path  = '/scratch/user/troyarcomano/Predictions/ML_only/'\n",
    "\n",
    "parallel_files = get_files(path,parallel_pattern)\n",
    "parallel_truth_files = get_files(path,parallel_truth_pattern)\n",
    "\n",
    "truth_files = sorted(truth_files)\n",
    "hybrid_files = sorted(hybrid_files)\n",
    "speedy_files = sorted(speedy_files)\n",
    "parallel_files = sorted(parallel_files)\n",
    "parallel_truth_files = sorted(parallel_truth_files)\n",
    "\n",
    "plot_times = np.array([24,48,72])\n",
    "height_level = slice(0,8)#Sigma level\n",
    "\n",
    "speedy_files = speedy_files\n",
    "hybrid_files = hybrid_files\n",
    "truth_files = truth_files\n",
    "\n",
    "speedy_files = ['/scratch/user/troyarcomano/Predictions/Hybrid/speedy_era_start01_07_2000_01.nc']\n",
    "hybrid_files = ['/scratch/user/troyarcomano/Predictions/Hybrid/hybrid_prediction_era6000_20_20_20_beta_res0.1_beta_model_1.0_prior_1.0_overlap1_era5_6hrtimestep_19years_climate_simulation_t_ends_2000_tisrtrial_12_30_1999_00.nc']\n",
    "#hybrid_files = ['/scratch/user/troyarcomano/Predictions/Hybrid/hybrid_prediction_era6000_20_20_20_beta_res0.1_beta_model_1.0_prior_1.0_overlap1_era5_6hrtimestep_19years_climate_simulation_t_ends_2000trial_12_30_1999_00.nc']\n",
    "\n",
    "power_spectra_plot(hybrid_files[0],'Temperature',height_level,18.75,20.411,speedy_file=speedy_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22c6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
